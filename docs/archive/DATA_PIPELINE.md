# 数据获取与处理指南

## 数据Pipeline概览

```
┌─────────────────────────────────────────────────────────────┐
│                     数据获取Pipeline                         │
├─────────────────────────────────────────────────────────────┤
│  Step 1: 搜索获取                                            │
│    ├─ 40+ 搜索关键词 (地理×菜系×场景)                          │
│    ├─ 质量预筛选 (评论≥5, 内容≥100字)                          │
│    └─ 保存原始数据 → raw/                                      │
│                                                              │
│  Step 2: 质量过滤                                            │
│    ├─ 硬性条件: 评论数/描述长度/时效性                         │
│    ├─ 垃圾检测: 广告关键词/可疑模式                           │
│    ├─ 质量评分: 0-100分 (互动+内容+作者+时效)                   │
│    └─ 保存过滤后数据 → data/filtered/                          │
│                                                              │
│  Step 3: 餐厅提取与去重                                       │
│    ├─ 从帖子中提取餐厅提及                                    │
│    ├─ 多层级去重:                                            │
│    │   ├─ Level 1: 精确匹配 (标准化名称+地址)                  │
│    │   ├─ Level 2: Fuzzy匹配 (名称相似度>0.8)                 │
│    │   └─ Level 3: Google Place ID匹配                       │
│    ├─ 合并同一餐厅的metrics数据                               │
│    └─ 输出去重数据库 → data/current/                           │
│                                                              │
│  Step 4: Google Places验证                                   │
│    ├─ 验证餐厅存在性                                         │
│    ├─ 获取准确地址和坐标                                      │
│    ├─ 获取官方评分和营业时间                                  │
│    └─ 更新最终数据库                                          │
└─────────────────────────────────────────────────────────────┘
```

## 快速开始

### 一键执行完整Pipeline

```bash
cd scripts
./pipeline.sh full
```

### 分步执行

```bash
cd scripts

# 1. 获取新数据 (小红书搜索)
./pipeline.sh fetch

# 2. 质量过滤
./pipeline.sh filter

# 3. 餐厅去重
./pipeline.sh dedupe

# 4. Google验证
./pipeline.sh validate

# 查看统计
./pipeline.sh stats
```

## 详细说明

### 1. 搜索获取 (fetch_xiaohongshu_data.sh)

**搜索策略:**
- 40+ 组合关键词覆盖地理、菜系、场景
- 每个关键词获取20个帖子
- 实时质量预筛选 (评论≥5条才获取详情)

**关键词矩阵:**
```
地理: 湾区、旧金山、南湾、Cupertino、Fremont、东湾、半岛...
菜系: 中餐、川菜、湘菜、火锅、烧烤、日料、韩餐、越南菜...
场景: 探店、约会、聚餐、一人食、外卖、踩雷、避雷、必吃...
```

### 2. 质量过滤 (filter_quality_posts.py)

**硬性过滤条件:**
| 条件 | 阈值 | 说明 |
|------|------|------|
| 评论数 | ≥5 | 排除无价值帖子 |
| 描述长度 | ≥50字 | 排除水贴 |
| 内容年龄 | ≤2年 | 保证时效性 |

**垃圾检测规则:**
- 广告关键词: "免费领取", "加我微信", "扫码", "限时优惠"...
- 可疑模式: 大量金钱符号、微信引流、异常互动比
- 内容过短检测

**质量评分算法 (0-100分):**
```
得分 = 互动指标(40分) + 内容深度(30分) + 作者可信度(20分) + 时效性(10分)

互动指标: 点赞/10 + 评论×2 + 收藏/2
内容深度: 描述长度/30 + 图片数×2
作者可信度: 粉丝数 + 获赞数
时效性: 30天内(10分), 90天内(7分), 180天内(5分)
```

### 3. 餐厅去重 (dedupe_restaurants.py)

**三级去重策略:**

#### Level 1: 精确匹配
```python
# 标准化名称和地址后精确匹配
normalize("王家味") == normalize("王家味")
```

#### Level 2: 别名映射
```python
ALIAS_MAP = {
    "王家卫": ["王家味"],
    "香锅大王": ["Sizzling Pot King", "Hunan House"],
    "留湘": ["Ping's Bistro"],
    ...
}
```

#### Level 3: Fuzzy匹配
- 名称相似度 > 0.8
- 地址相似度 > 0.5
- 认为是同一家餐厅

**数据合并逻辑:**
```python
# Discussion Volume: 直接累加
总互动量 = A互动量 + B互动量

# Sentiment: 加权平均
总分数 = (A正面+A中性×0.5 + B正面+B中性×0.5) / 总提及数

# Sources/Hightlights/Recommendations: 集合合并
来源 = A来源 ∪ B来源
```

### 4. Google验证

使用 `goplaces` CLI 工具:
```bash
goplaces search "餐厅名 地址" --json
goplaces details "place_id" --json
```

验证内容:
- ✅ 餐厅是否仍在营业
- ✅ 获取准确英文名称
- ✅ 获取完整地址和坐标
- ✅ 获取Google评分和价格等级
- ✅ 获取营业时间和电话

## 质量指标

### 目标数据质量标准

| 指标 | 当前 | 目标 | 说明 |
|------|------|------|------|
| 帖子数 | 4 | 100+ | 高质量帖子 |
| 餐厅数 | 21 | 100+ | 去重后 |
| 平均评论数/帖子 | 186 | 200+ | 数据丰富度 |
| 验证率 | 90% | 95%+ | Google验证 |
| 去重准确率 | - | >95% | 无重复餐厅 |

### 数据质量保证

**自动化检查:**
- 每日自动检测新帖子
- 每周更新metrics
- 每月全量重新验证

**人工抽样:**
- 每周随机抽取10%数据人工检查
- 重点关注争议餐厅 (sentiment 0.4-0.7)

## 常见问题

### Q: 为什么只从小红书获取数据?
**A:** 小红书用户分享的内容更详细、更真实。未来可以扩展:
- Yelp API (英文评价)
- Google Reviews (官方数据)
- 大众点评 (中文评价)

### Q: 如何处理同一餐厅的不同分店?
**A:** 使用地址区分:
- 地址不同 → 不同条目
- 同一`place_id` → 合并
- 模糊地址 → 标记待验证

### Q: 数据多久更新一次?
**A:** 
- 增量更新: 每周自动运行pipeline
- 全量验证: 每月重新Google验证
- 紧急修正: 用户反馈后24小时内

### Q: 如何保证数据不重复?
**A:** 三重保障:
1. Fuzzy matching算法
2. Google Place ID唯一性
3. 人工定期检查

## 脚本清单

| 脚本 | 用途 | 调用方式 |
|------|------|----------|
| `fetch_xiaohongshu_data.sh` | 批量搜索获取 | `./pipeline.sh fetch` |
| `filter_quality_posts.py` | 质量过滤 | `./pipeline.sh filter` |
| `dedupe_restaurants.py` | 餐厅去重 | `./pipeline.sh dedupe` |
| `pipeline.sh` | 完整pipeline | `./pipeline.sh full` |

## 扩展计划

### Phase 1: 数据扩展 (本周)
- [ ] 执行完整pipeline获取100+帖子
- [ ] 优化去重算法，减少误判
- [ ] 建立自动定时任务

### Phase 2: 质量提升 (下周)
- [ ] 增加Yelp数据交叉验证
- [ ] 建立餐厅变更监控 (开业/关门)
- [ ] 用户反馈机制

### Phase 3: 智能分析 (未来)
- [ ] 菜品级别sentiment分析
- [ ] 价格趋势追踪
- [ ] 个性化推荐算法

---

**最后更新:** 2026-02-15  
**数据版本:** v3.0-pipeline-ready