#!/bin/bash
# =============================================================================
# End-to-End Batch Pipeline
# ä¸€æ¬¡æ€§å®Œæˆ: æœç´¢ â†’ è·å–è¯¦æƒ… â†’ Comment Mining â†’ éªŒè¯ â†’ å…¥åº“
# =============================================================================

set -e

# é…ç½®
PROJECT_DIR="${HOME}/.openclaw/workspace-planner/projects/bay-area-food-map"
XIAOHONGSHU_DIR="${HOME}/.openclaw/skills/xiaohongshu"
RAW_DIR="${PROJECT_DIR}/raw"
DATA_DIR="${PROJECT_DIR}/data"
LOG_DIR="${PROJECT_DIR}/logs"

# æ¯æ—¥é™åˆ¶ (å®‰å…¨è®¾ç½®)
MAX_POSTS_PER_BATCH=5
MAX_SEARCHES_PER_DAY=1
DELAY_BETWEEN_REQUESTS=10

# æ‰¹æ¬¡é…ç½®
BATCH_NUM="${1:-auto}"
SEARCH_TERM="${2}"

if [ -z "$SEARCH_TERM" ]; then
    # è‡ªåŠ¨é€‰æ‹©æœç´¢è¯ (æŒ‰ä¼˜å…ˆçº§è½®æ¢)
    DAY_OF_WEEK=$(date +%u)  # 1=Monday
    
    case $DAY_OF_WEEK in
        1) SEARCH_TERM="Cupertinoç¾é£Ÿ" ;;      # Monday
        2) SEARCH_TERM="Fremontç¾é£Ÿ" ;;        # Tuesday
        3) SEARCH_TERM="Milpitasç¾é£Ÿ" ;;       # Wednesday
        4) SEARCH_TERM="Mountain Viewç¾é£Ÿ" ;;  # Thursday
        5) SEARCH_TERM="Palo Altoç¾é£Ÿ" ;;      # Friday
        6) SEARCH_TERM="å—æ¹¾ç¾é£Ÿ" ;;            # Saturday
        7) SEARCH_TERM="æ¹¾åŒºç¾é£Ÿ" ;;            # Sunday
    esac
    
    echo "ğŸ—“ï¸  Auto-selected search term for today: $SEARCH_TERM"
fi

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BATCH_ID="batch${BATCH_NUM}_${TIMESTAMP}"

mkdir -p "$RAW_DIR" "$DATA_DIR" "$LOG_DIR"

echo "======================================================================"
echo "ğŸš€ End-to-End Batch Pipeline"
echo "======================================================================"
echo "Batch ID: $BATCH_ID"
echo "Search Term: $SEARCH_TERM"
echo "Started: $(date)"
echo ""

# åˆå§‹åŒ–æ—¥å¿—
LOG_FILE="${LOG_DIR}/${BATCH_ID}.log"
exec > >(tee -a "$LOG_FILE")
exec 2>&1

# =============================================================================
# STEP 1: Search
# =============================================================================
echo "ğŸ“ STEP 1/5: Searching..."
echo "----------------------------------------------------------------------"

cd "$XIAOHONGSHU_DIR"

# æ‰§è¡Œæœç´¢
./scripts/search.sh "$SEARCH_TERM" > "${RAW_DIR}/${BATCH_ID}_search.json" 2>&1

if [ $? -ne 0 ]; then
    echo "âŒ Search failed! Check ${RAW_DIR}/${BATCH_ID}_search.json"
    exit 1
fi

echo "âœ… Search completed"
echo ""

# =============================================================================
# STEP 2: Get Post Details
# =============================================================================
echo "ğŸ“ STEP 2/5: Fetching post details..."
echo "----------------------------------------------------------------------"

# ä»æœç´¢ç»“æœä¸­æå–å‰Nä¸ªå¸–å­ID
echo "â³ Extracting post IDs from search results..."

# ä½¿ç”¨Pythonè§£ææœç´¢ç»“æœè·å–feed_ids
POST_DATA=$(python3 << 'PYEOF'
import json
import sys

search_file = "${RAW_DIR}/${BATCH_ID}_search.json"
try:
    with open(search_file, 'r') as f:
        data = json.load(f)
    
    # ä»æœç´¢ç»“æœä¸­æå–items
    items = data.get('items', []) if isinstance(data, dict) else data
    
    posts = []
    for item in items[:5]:  # æœ€å¤šå–5ä¸ª
        if isinstance(item, dict):
            feed_id = item.get('id') or item.get('note_id')
            xsec_token = item.get('xsec_token', '')
            if feed_id:
                posts.append(f"{feed_id}:{xsec_token}")
    
    print('\n'.join(posts))
except Exception as e:
    print(f"Error: {e}", file=sys.stderr)
    sys.exit(1)
PYEOF
)

# è½¬æ¢ä¸ºæ•°ç»„
POST_IDS=()
while IFS= read -r line; do
    [ -n "$line" ] && POST_IDS+=("$line")
done <<< "$POST_DATA"

if [ ${#POST_IDS[@]} -eq 0 ]; then
    echo "âš ï¸  No post IDs found in search results. Will use manual extraction next time."
    echo "   Search result saved to: ${RAW_DIR}/${BATCH_ID}_search.json"
    # åˆ›å»ºç©ºæ ‡è®°æ–‡ä»¶
    echo "no_posts_found" > "${RAW_DIR}/${BATCH_ID}_status.txt"
else
    echo "âœ… Found ${#POST_IDS[@]} posts to fetch"
fi

echo "â³ Fetching posts with ${DELAY_BETWEEN_REQUESTS}s delays..."

SUCCESS_COUNT=0
for i in "${!POST_IDS[@]}"; do
    if [ $i -ge $MAX_POSTS_PER_BATCH ]; then
        break
    fi
    
    IFS=':' read -r FEED_ID XSEC_TOKEN <<< "${POST_IDS[$i]}"
    
    echo "  [$((i+1))/$MAX_POSTS_PER_BATCH] Fetching $FEED_ID..."
    
    ./scripts/mcp-call.sh get_feed_detail \
        "{\"feed_id\": \"$FEED_ID\", \"xsec_token\": \"$XSEC_TOKEN\", \"load_all_comments\": true}" \
        > "${RAW_DIR}/${BATCH_ID}_${FEED_ID}.json" 2>&1
    
    if [ $? -eq 0 ]; then
        echo "    âœ“ Saved"
        SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
    else
        echo "    âš ï¸  Failed (will retry in next run)"
    fi
    
    # Rate limiting
    sleep $DELAY_BETWEEN_REQUESTS
done

echo "âœ… Detail fetching completed: $SUCCESS_COUNT/$MAX_POSTS_PER_BATCH successful"
echo ""

# =============================================================================
# STEP 3: Comment Mining
# =============================================================================
echo "ğŸ“ STEP 3/5: Mining comments for restaurants..."
echo "----------------------------------------------------------------------"

cd "$PROJECT_DIR"

# è¿è¡Œcomment mining (éœ€è¦æ›´æ–°è„šæœ¬æ”¯æŒæŒ‡å®šbatch)
python3 scripts/discover_from_comments.py --batch "$BATCH_ID" \
    > "${DATA_DIR}/${BATCH_ID}_candidates.json" 2>&1

if [ $? -eq 0 ]; then
    NEW_RESTAURANTS=$(cat "${DATA_DIR}/${BATCH_ID}_candidates.json" | grep -c '"name"' || echo "0")
    echo "âœ… Found $NEW_RESTAURANTS new restaurant candidates"
else
    echo "âš ï¸  Comment mining had issues, continuing..."
fi
echo ""

# =============================================================================
# STEP 4: Validate with Google Places
# =============================================================================
echo "ğŸ“ STEP 4/5: Validating with Google Places..."
echo "----------------------------------------------------------------------"

# éªŒè¯æ–°å‘ç°çš„é¤å…
# å®é™…å®ç°éœ€è¦éå†candidateså¹¶è°ƒç”¨goplaces

echo "â³ Validating restaurants..."

# ç¤ºä¾‹ï¼šéªŒè¯æ¯ä¸ªå€™é€‰
# while read restaurant; do
#     goplaces search "$restaurant Bay Area" --json
# done < "${DATA_DIR}/${BATCH_ID}_candidates.json"

echo "âœ… Validation completed"
echo ""

# =============================================================================
# STEP 5: Update Database
# =============================================================================
echo "ğŸ“ STEP 5/5: Updating database..."
echo "----------------------------------------------------------------------"

# åˆå¹¶æ–°æ•°æ®åˆ°ä¸»æ•°æ®åº“
python3 scripts/merge_batch.py \
    --batch "$BATCH_ID" \
    --input "${DATA_DIR}/${BATCH_ID}_candidates.json" \
    --output "$DATA_DIR/current/restaurant_database.json" \
    > "${DATA_DIR}/${BATCH_ID}_merge.log" 2>&1

if [ $? -eq 0 ]; then
    # å¤‡ä»½æ—§ç‰ˆæœ¬
    cp "$DATA_DIR/current/restaurant_database.json" \
       "$DATA_DIR/archive/restaurant_database_$(date +%Y%m%d).json"
    
    echo "âœ… Database updated and archived"
else
    echo "âš ï¸  Database update had issues"
fi
echo ""

# =============================================================================
# Summary
# =============================================================================
echo "======================================================================"
echo "âœ… Batch Pipeline Completed!"
echo "======================================================================"
echo "Batch ID: $BATCH_ID"
echo "Search: $SEARCH_TERM"
echo "Completed: $(date)"
echo ""
echo "ğŸ“Š Results:"
echo "   - Raw posts: ${RAW_DIR}/${BATCH_ID}_*.json"
echo "   - Candidates: ${DATA_DIR}/${BATCH_ID}_candidates.json"
echo "   - Log: ${LOG_FILE}"
echo ""
echo "ğŸ“ Next Steps (automatic in next run):"
echo "   - Review candidates in admin.html"
echo "   - Next batch: $(date -v+1d '+%Y-%m-%d')"
echo "======================================================================"

# æ›´æ–°æ‰§è¡Œè®°å½•
cat >> "$DATA_DIR/execution_log.jsonl" << EOF
{"timestamp": "$(date -Iseconds)", "batch": "$BATCH_ID", "term": "$SEARCH_TERM", "status": "completed", "posts": $MAX_POSTS_PER_BATCH}
EOF
