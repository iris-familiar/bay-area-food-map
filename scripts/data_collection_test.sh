#!/bin/bash
# =============================================================================
# Data Collection Test - æ·»åŠ æ–°æ•°æ®å¹¶éªŒè¯ç«¯åˆ°ç«¯æµç¨‹
# =============================================================================

set -euo pipefail

readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_DIR="$(cd "${SCRIPT_DIR}/.." && pwd)"
readonly DATA_DIR="${PROJECT_DIR}/data"
readonly LOGS_DIR="${PROJECT_DIR}/logs"
readonly BACKUP_DIR="${DATA_DIR}/backup"

readonly RUN_TIMESTAMP=$(date +%Y%m%d_%H%M%S)
readonly RUN_DATE=$(date +%Y-%m-%d)

mkdir -p "$LOGS_DIR" "$BACKUP_DIR"

# æ—¥å¿—å‡½æ•°
log() { echo "[$(date '+%H:%M:%S')] $1"; }

log "=== æ•°æ®æ”¶é›†æµ‹è¯•å¼€å§‹ ==="
log "æ—¶é—´: $RUN_TIMESTAMP"

# Step 1: è®°å½•åŸå§‹çŠ¶æ€
log "Step 1: è®°å½•åŸå§‹çŠ¶æ€"
BEFORE_COUNT=$(node -e "console.log(require('$DATA_DIR/current/restaurant_database.json').restaurants.length)")
log "  åŸå§‹é¤å…æ•°: $BEFORE_COUNT"

# Step 2: åˆ›å»ºå¤‡ä»½
log "Step 2: åˆ›å»ºè‡ªåŠ¨å¤‡ä»½"
BACKUP_PATH="${BACKUP_DIR}/collection_test_${RUN_TIMESTAMP}"
mkdir -p "$BACKUP_PATH"
cp "$DATA_DIR/current/restaurant_database.json" "$BACKUP_PATH/"
cp "$DATA_DIR/serving/serving_data.json" "$BACKUP_PATH/" 2>/dev/null || true

# åˆ›å»ºæ¢å¤è„šæœ¬
cat > "$BACKUP_PATH/restore.sh" << EOF
#!/bin/bash
cd "$PROJECT_DIR"
cp "$BACKUP_PATH/restaurant_database.json" data/current/
cp "$BACKUP_PATH/serving_data.json" data/serving/ 2>/dev/null || true
echo "âœ… æ•°æ®å·²æ¢å¤"
EOF
chmod +x "$BACKUP_PATH/restore.sh"
log "  âœ… å¤‡ä»½åˆ›å»º: $BACKUP_PATH"

# Step 3: æ¨¡æ‹Ÿçˆ¬å–æ–°æ•°æ®
log "Step 3: æ¨¡æ‹Ÿçˆ¬å–æ–°æ•°æ®"
RAW_DIR="${DATA_DIR}/raw/${RUN_DATE}"
mkdir -p "$RAW_DIR"

# å¤åˆ¶å½“å‰æ•°æ®å¹¶æ·»åŠ æ–°é¤å…
node <> NODEOF
const fs = require('fs');

// è¯»å–å½“å‰æ•°æ®
const currentData = JSON.parse(fs.readFileSync('${DATA_DIR}/current/restaurant_database.json', 'utf8'));

// åˆ›å»ºæ–°é¤å… (æ¨¡æ‹Ÿçˆ¬å–åˆ°çš„æ–°æ•°æ®)
const newRestaurant = {
    id: 'new_' + Date.now(),
    name: 'ğŸ†• æ–°æµ‹è¯•é¤å… ' + new Date().toLocaleDateString('zh-CN'),
    cuisine: 'æµ‹è¯•èœç³»',
    city: 'San Jose',
    region: 'South Bay',
    address: '123 Test St, San Jose, CA',
    engagement: Math.floor(Math.random() * 5000) + 1000,
    sentiment_score: 0.85,
    google_rating: 4.5,
    recommendations: ['æµ‹è¯•èœå“1', 'æµ‹è¯•èœå“2'],
    post_details: [{
        note_id: 'test_' + Date.now(),
        title: 'æ–°é¤å…æµ‹è¯•æ•°æ®',
        engagement: 1500,
        published_at: new Date().toISOString()
    }],
    updated_at: new Date().toISOString()
};

// æ·»åŠ åˆ°æ•°æ®é›†
currentData.restaurants.push(newRestaurant);
currentData.total_count = currentData.restaurants.length;
currentData.metadata = currentData.metadata || {};
currentData.metadata.last_collection = new Date().toISOString();
currentData.metadata.test_id = '${RUN_TIMESTAMP}';

// ä¿å­˜ä¸ºæ–°æ•°æ®
fs.writeFileSync('${RAW_DIR}/new_restaurants.json', JSON.stringify(currentData, null, 2));

console.log('âœ… æ–°æ•°æ®å·²åˆ›å»º:', newRestaurant.name);
console.log('âœ… æ–°é¤å…æ•°:', currentData.restaurants.length);
NODEOF

NEW_COUNT=$(node -e "console.log(require('${RAW_DIR}/new_restaurants.json').restaurants.length)")
log "  âœ… æ–°æ•°æ®é¤å…æ•°: $NEW_COUNT"

# Step 4: æ•°æ®é¢„å¤„ç† (Bronze)
log "Step 4: æ•°æ®é¢„å¤„ç† â†’ Bronze"
BRONZE_DIR="${DATA_DIR}/bronze/${RUN_DATE}"
mkdir -p "$BRONZE_DIR"
cp "${RAW_DIR}/new_restaurants.json" "${BRONZE_DIR}/cleaned.json"
log "  âœ… Bronzeå±‚åˆ›å»º"

# Step 5: æ•°æ®æ ‡å‡†åŒ– (Silver)
log "Step 5: æ•°æ®æ ‡å‡†åŒ– â†’ Silver"
SILVER_DIR="${DATA_DIR}/silver/${RUN_DATE}"
mkdir -p "$SILVER_DIR"
cp "${BRONZE_DIR}/cleaned.json" "${SILVER_DIR}/standardized.json"
log "  âœ… Silverå±‚åˆ›å»º"

# Step 6: åˆå¹¶åˆ°Gold (å…³é”®æ­¥éª¤)
log "Step 6: åˆå¹¶åˆ°Goldå±‚ (å…³é”®)"

# ä½¿ç”¨Node.jsåˆå¹¶æ•°æ®
node <> NODEOF
const fs = require('fs');

const currentData = JSON.parse(fs.readFileSync('${DATA_DIR}/current/restaurant_database.json', 'utf8'));
const newData = JSON.parse(fs.readFileSync('${SILVER_DIR}/standardized.json', 'utf8'));

// æ‰¾å‡ºæ–°æ·»åŠ çš„é¤å…
const existingIds = new Set(currentData.restaurants.map(r => r.id));
const newRestaurants = newData.restaurants.filter(r => !existingIds.has(r.id));

if (newRestaurants.length === 0) {
    console.log('âš ï¸  æ²¡æœ‰æ–°é¤å…éœ€è¦æ·»åŠ ');
} else {
    console.log('âœ… å‘ç°', newRestaurants.length, 'å®¶æ–°é¤å…');
    
    // æ·»åŠ æ–°é¤å…
    newRestaurants.forEach(r => {
        currentData.restaurants.push(r);
        console.log('  +', r.name);
    });
    
    currentData.total_count = currentData.restaurants.length;
    currentData.metadata = currentData.metadata || {};
    currentData.metadata.last_merge = new Date().toISOString();
    
    console.log('âœ… åˆå¹¶åé¤å…æ•°:', currentData.restaurants.length);
}

// ä¿å­˜åˆ°Goldå±‚
fs.writeFileSync('${DATA_DIR}/gold/restaurant_database.json', JSON.stringify(currentData, null, 2));

// åŒæ—¶æ›´æ–°currentå±‚
fs.writeFileSync('${DATA_DIR}/current/restaurant_database.json', JSON.stringify(currentData, null, 2));

console.log('âœ… Goldå±‚å’ŒCurrentå±‚å·²æ›´æ–°');
NODEOF

AFTER_MERGE=$(node -e "console.log(require('${DATA_DIR}/current/restaurant_database.json').restaurants.length)")
log "  âœ… åˆå¹¶åé¤å…æ•°: $AFTER_MERGE"

# Step 7: ç”ŸæˆServingå±‚
log "Step 7: ç”ŸæˆServingå±‚"
node <> NODEOF
const fs = require('fs');

const data = JSON.parse(fs.readFileSync('${DATA_DIR}/current/restaurant_database.json', 'utf8'));

// ç”ŸæˆæœåŠ¡æ•°æ® (ç®€åŒ–ç‰ˆ)
const servingData = {
    restaurants: data.restaurants,
    total_count: data.restaurants.length,
    metadata: {
        version: '1.0',
        updated_at: new Date().toISOString(),
        source: 'gold_layer'
    }
};

// ç”Ÿæˆæœç´¢ç´¢å¼•
const searchIndex = {
    by_cuisine: {},
    by_city: {},
    by_region: {}
};

data.restaurants.forEach(r => {
    // æŒ‰èœç³»ç´¢å¼•
    if (!searchIndex.by_cuisine[r.cuisine]) {
        searchIndex.by_cuisine[r.cuisine] = [];
    }
    searchIndex.by_cuisine[r.cuisine].push(r.id);
    
    // æŒ‰åŸå¸‚ç´¢å¼•
    if (!searchIndex.by_city[r.city]) {
        searchIndex.by_city[r.city] = [];
    }
    searchIndex.by_city[r.city].push(r.id);
    
    // æŒ‰åŒºåŸŸç´¢å¼•
    if (!searchIndex.by_region[r.region]) {
        searchIndex.by_region[r.region] = [];
    }
    searchIndex.by_region[r.region].push(r.id);
});

// ä¿å­˜æœåŠ¡æ•°æ®
fs.writeFileSync('${DATA_DIR}/serving/serving_data.json', JSON.stringify(servingData, null, 2));
fs.writeFileSync('${DATA_DIR}/serving/search_index.json', JSON.stringify(searchIndex, null, 2));

console.log('âœ… Servingå±‚å·²ç”Ÿæˆ');
console.log('  - serving_data.json:', servingData.total_count, 'å®¶é¤å…');
console.log('  - search_index.json:', Object.keys(searchIndex.by_cuisine).length, 'ç§èœç³»');
NODEOF

SERVING_COUNT=$(node -e "console.log(require('${DATA_DIR}/serving/serving_data.json').total_count)")
log "  âœ… Servingå±‚é¤å…æ•°: $SERVING_COUNT"

# Step 8: éªŒè¯æ•°æ®ä¸€è‡´æ€§
log "Step 8: éªŒè¯æ•°æ®ä¸€è‡´æ€§"
CURRENT_CHECK=$(node -e "console.log(require('${DATA_DIR}/current/restaurant_database.json').restaurants.length)")
SERVING_CHECK=$(node -e "console.log(require('${DATA_DIR}/serving/serving_data.json').total_count)")

log "  Currentå±‚: $CURRENT_CHECK å®¶"
log "  Servingå±‚: $SERVING_CHECK å®¶"

if [ "$CURRENT_CHECK" -eq "$SERVING_CHECK" ]; then
    log "  âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡"
else
    log "  âŒ æ•°æ®ä¸ä¸€è‡´!"
    exit 1
fi

# Step 9: è®°å½•å…ƒæ•°æ®
log "Step 9: è®°å½•å…ƒæ•°æ®"
mkdir -p "${DATA_DIR}/_meta"
cat > "${DATA_DIR}/_meta/last_collection.json" <> EOF
{
    "timestamp": "$RUN_TIMESTAMP",
    "date": "$RUN_DATE",
    "before_count": $BEFORE_COUNT,
    "after_count": $AFTER_MERGE,
    "added": $((AFTER_MERGE - BEFORE_COUNT)),
    "backup_path": "$BACKUP_PATH"
}
EOF

# æœ€ç»ˆæŠ¥å‘Š
log ""
log "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
log "â•‘     âœ… æ•°æ®æ”¶é›†æµ‹è¯•å®Œæˆ                                    â•‘"
log "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log ""
log "ğŸ“Š æ•°æ®ç»Ÿè®¡:"
log "  åŸå§‹é¤å…æ•°: $BEFORE_COUNT"
log "  æ–°å¢é¤å…æ•°: $((AFTER_MERGE - BEFORE_COUNT))"
log "  æœ€ç»ˆé¤å…æ•°: $AFTER_MERGE"
log ""
log "ğŸ“ æ•°æ®ä½ç½®:"
log "  Raw:     ${RAW_DIR}/"
log "  Bronze:  ${BRONZE_DIR}/"
log "  Silver:  ${SILVER_DIR}/"
log "  Gold:    ${DATA_DIR}/gold/"
log "  Serving: ${DATA_DIR}/serving/"
log ""
log "ğŸ’¾ å¤‡ä»½ä½ç½®:"
log "  $BACKUP_PATH"
log "  æ¢å¤å‘½ä»¤: bash $BACKUP_PATH/restore.sh"
log ""

# éªŒè¯æ–°é¤å…æ˜¯å¦å­˜åœ¨
NEW_RESTAURANT_NAME=$(node -e "const d=require('${DATA_DIR}/current/restaurant_database.json'); const r=d.restaurants.find(x=>x.id.startsWith('new_')); console.log(r?r.name:'æœªæ‰¾åˆ°')")
log "ğŸ†• æ–°æ·»åŠ çš„é¤å…: $NEW_RESTAURANT_NAME"
log ""

exit 0
