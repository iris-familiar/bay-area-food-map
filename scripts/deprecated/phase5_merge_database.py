#!/usr/bin/env python3
"""
Phase 5: åˆå¹¶æ–°æå–æ•°æ®åˆ°ç°æœ‰v5æ•°æ®åº“
å¹¶æ›´æ–°ç»Ÿè®¡æ•°æ®
"""
import json
from pathlib import Path
from datetime import datetime

# åŠ è½½ç°æœ‰v5æ•°æ®åº“
with open('data/current/restaurant_database_v5_llm_extracted.json') as f:
    existing_db = json.load(f)

# åŠ è½½æ–°æå–çš„æ•°æ®
with open('data/extracted_restaurants_kimi_v3.json') as f:
    new_extractions = json.load(f)

print('='*70)
print('ğŸ”„ Phase 5: åˆå¹¶æ•°æ®åˆ°v5æ•°æ®åº“')
print('='*70)

print(f'\nğŸ“Š ç°æœ‰æ•°æ®åº“: {existing_db["statistics"]["total_restaurants"]} å®¶é¤å…')
print(f'ğŸ“Š æ–°æå–æ•°æ®: {new_extractions["restaurants_count"]} å®¶é¤å…')

# åˆ›å»ºåç§°æ˜ å°„ï¼Œé¿å…é‡å¤
existing_names = {r['name'].lower(): r for r in existing_db['restaurants']}

new_count = 0
merged_count = 0

for new_r in new_extractions['restaurants']:
    name = new_r['name']
    name_lower = name.lower()
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if name_lower in existing_names:
        # åˆå¹¶æ•°æ®
        existing = existing_names[name_lower]
        existing['mention_count'] = existing.get('mention_count', 0) + new_r.get('unique_post_count', 1)
        existing['engagement'] = existing.get('engagement', 0) + new_r['engagement'].get('collected', 0)
        
        # æ·»åŠ ä¸Šä¸‹æ–‡
        if 'llmMentions' not in existing:
            existing['llmMentions'] = []
        
        for ctx in new_r.get('contexts', []):
            if ctx and ctx not in [m.get('context', '') for m in existing['llmMentions']]:
                existing['llmMentions'].append({
                    'confidence': 0.85,
                    'context': ctx[:200],
                    'sentiment': 'positive',
                    'source': 'kimi_semantic_v3'
                })
        
        merged_count += 1
    else:
        # åˆ›å»ºæ–°é¤å…è®°å½•
        max_id = max([int(r['id'][1:]) for r in existing_db['restaurants']])
        new_id = f'r{max_id + new_count + 1:03d}'
        
        # ä»ä¸Šä¸‹æ–‡æå–åŸå¸‚
        city = 'Bay Area'
        for ctx in new_r.get('contexts', []):
            ctx_str = str(ctx)
            for c in ['Cupertino', 'Fremont', 'Sunnyvale', 'Milpitas', 'San Jose']:
                if c in ctx_str:
                    city = c
                    break
        
        # æå–èœå“
        dishes = []
        dish_keywords = ['çƒ¤é±¼', 'é…¸èœé±¼', 'çƒ¤è‚‰', 'æ—©èŒ¶', 'è‚ ç²‰', 'é¥ºå­', 'é¢æ¡', 'ç«é”…']
        for ctx in new_r.get('contexts', []):
            for dish in dish_keywords:
                if dish in str(ctx) and dish not in dishes:
                    dishes.append(dish)
        
        restaurant = {
            'id': new_id,
            'name': name,
            'nameEn': name,
            'type': 'ä¸­é¤',
            'cuisine': 'å¾…ç¡®è®¤',
            'area': city,
            'location': city,
            'status': 'candidate',
            'verified': False,
            'price_range': '$$',
            'mention_count': new_r.get('unique_post_count', 1),
            'engagement': new_r['engagement'].get('collected', 0),
            'llmMentions': [{
                'confidence': 0.85,
                'context': ctx[:200] if ctx else f'ä»å¸–å­ä¸­æå–: {name}',
                'sentiment': 'positive',
                'source': 'kimi_semantic_v3'
            } for ctx in new_r.get('contexts', [])[:1]],
            'popular_dishes': dishes if dishes else ['ç‰¹è‰²èœ'],
            'sentiment_score': min(new_r['engagement'].get('collected', 0) / 100, 1.0),
            'metrics': {
                'mention_count': new_r.get('unique_post_count', 1),
                'total_engagement': new_r['engagement'].get('collected', 0) + new_r['engagement'].get('comments', 0) * 2
            }
        }
        
        existing_db['restaurants'].append(restaurant)
        existing_names[name_lower] = restaurant
        new_count += 1

# æ›´æ–°ç»Ÿè®¡æ•°æ®
existing_db['version'] = '5.2-merged'
existing_db['updated_at'] = datetime.now().isoformat()
existing_db['data_source']['merged_extraction'] = {
    'method': 'Kimi_semantic_v3',
    'restaurants_added': new_count,
    'restaurants_merged': merged_count,
    'merged_at': datetime.now().isoformat()
}

existing_db['statistics']['total_restaurants'] = len(existing_db['restaurants'])

# ä¿å­˜åˆå¹¶åçš„æ•°æ®åº“
with open('data/current/restaurant_database_v5.json', 'w') as f:
    json.dump(existing_db, f, ensure_ascii=False, indent=2)

print(f'\nâœ… åˆå¹¶å®Œæˆ!')
print(f'   æ–°å¢é¤å…: {new_count} å®¶')
print(f'   åˆå¹¶æ›´æ–°: {merged_count} å®¶')
print(f'   æ€»è®¡: {len(existing_db["restaurants"])} å®¶')
print(f'   ä¿å­˜è‡³: data/current/restaurant_database_v5.json')

# å¯¼å‡ºç®€åŒ–ç‰ˆç”¨äºUI
print('\nğŸ“ ç”ŸæˆUIç®€åŒ–ç‰ˆ...')
ui_restaurants = []
for r in existing_db['restaurants']:
    # è®¡ç®—è¶‹åŠ¿
    mentions = r.get('mention_count', 0)
    engagement = r.get('engagement', 0)
    
    ui_restaurants.append({
        'id': r['id'],
        'name': r['name'],
        'nameEn': r.get('nameEn', r['name']),
        'cuisine': r.get('cuisine', 'å¾…ç¡®è®¤'),
        'area': r.get('area', 'æ¹¾åŒº'),
        'verified': r.get('verified', False),
        'price_range': r.get('price_range', '$$'),
        'sentiment_score': r.get('sentiment_score', 0.7),
        'popular_dishes': r.get('popular_dishes', ['ç‰¹è‰²èœ']),
        'trend_7d': min(mentions * 10, 100),
        'trend_30d': min(engagement // 2, 100),
        'total_engagement': engagement + mentions * 10,
        'mention_count': mentions
    })

# æŒ‰äº’åŠ¨æ•°æ’åº
ui_restaurants.sort(key=lambda x: x['total_engagement'], reverse=True)

ui_data = {
    'version': '5.2',
    'updated_at': datetime.now().isoformat(),
    'total': len(ui_restaurants),
    'restaurants': ui_restaurants
}

with open('data/current/restaurant_database_v5_ui.json', 'w') as f:
    json.dump(ui_data, f, ensure_ascii=False, indent=2)

print(f'   UIæ•°æ®å·²ä¿å­˜: {len(ui_restaurants)} å®¶é¤å…')

print('\n' + '='*70)
print('âœ… Phase 5 å®Œæˆ!')
print('='*70)
