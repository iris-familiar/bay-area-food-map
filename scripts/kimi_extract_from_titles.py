#!/usr/bin/env python3
import json
import re
from collections import defaultdict

with open('data/raw/phase1a_search_results.json') as f:
    data = json.load(f)

posts = data.get('posts', [])
print(f'ğŸ¤– åŸºäº{len(posts)}æ¡å¸–å­æ ‡é¢˜è¿›è¡Œè¯­ä¹‰æå–...')
print('=' * 70)

# å­˜å‚¨æå–çš„é¤å…
extracted_restaurants = defaultdict(lambda: {
    'mentions': [],
    'total_engagement': 0,
    'cities': set(),
    'confidence': 0
})

for post in posts:
    post_id = post.get('id')
    title = post.get('title', '')
    city = post.get('city', '')
    engagement = int(post.get('likedCount', 0)) + int(post.get('commentCount', 0)) + int(post.get('collectedCount', 0))
    
    # Kimiè¯­ä¹‰åˆ†æï¼šä»æ ‡é¢˜æå–é¤å…å
    # æ¨¡å¼1: "åŸå¸‚ï½œXXX" - XXXæ˜¯é¤å…åæˆ–ä¸»é¢˜
    if 'ï½œ' in title:
        parts = title.split('ï½œ')
        if len(parts) >= 2:
            potential = parts[1].strip()
            # æ¸…ç†emojiå’Œç¬¦å·
            clean = re.sub(r'[ğŸ±ğŸ¥˜ğŸœğŸ¤ğŸ”¥ğŸ§¨ğŸ˜‹ğŸã€ã€‘]+', ' ', potential).strip()
            if clean and len(clean) > 2:
                # åˆ¤æ–­æ˜¯å¦åŒ…å«é¤å…åï¼ˆè¯­ä¹‰åˆ¤æ–­ï¼‰
                if any(keyword in clean for keyword in ['é¤å…', 'åº—', 'é¦†', 'å±‹', 'å®¶', 'é£Ÿå ‚', 'å¨æˆ¿']):
                    restaurant_name = clean.split()[0] if ' ' in clean else clean
                    print(f'\nğŸ“ æå–é¤å…: {restaurant_name}')
                    print(f'   æ¥æºæ ‡é¢˜: {title[:60]}')
                    print(f'   åŸå¸‚: {city}')
                    liked = post.get('likedCount', 0)
                    comment = post.get('commentCount', 0)
                    collected = post.get('collectedCount', 0)
                    print(f'   äº’åŠ¨: ğŸ‘{liked} ğŸ’¬{comment} ğŸ”–{collected}')
                    
                    extracted_restaurants[restaurant_name]['mentions'].append({
                        'post_id': post_id,
                        'context': title,
                        'engagement': engagement
                    })
                    extracted_restaurants[restaurant_name]['total_engagement'] += engagement
                    extracted_restaurants[restaurant_name]['cities'].add(city)

# ç»Ÿè®¡
print(f'\n{"="*70}')
print(f'âœ… ä»æ ‡é¢˜ä¸­æå–äº† {len(extracted_restaurants)} å®¶é¤å…å€™é€‰')
print(f'\nTop 10 æŒ‰è®¨è®ºåº¦æ’åº:')
sorted_restaurants = sorted(extracted_restaurants.items(), 
                            key=lambda x: x[1]['total_engagement'], 
                            reverse=True)[:10]

for name, info in sorted_restaurants:
    cities = ', '.join(info['cities'])
    mentions = len(info['mentions'])
    eng = info['total_engagement']
    print(f'  {name} ({cities}): {eng} äº’åŠ¨, {mentions} æ¬¡æåŠ')

# ä¿å­˜ç»“æœ
result = {
    'extracted_from': 'title_semantic_analysis',
    'total_posts': len(posts),
    'total_restaurants': len(extracted_restaurants),
    'restaurants': [
        {
            'name': name,
            'cities': list(info['cities']),
            'total_engagement': info['total_engagement'],
            'mention_count': len(info['mentions']),
            'confidence': 'medium'  # åŸºäºæ ‡é¢˜çš„ç½®ä¿¡åº¦ä¸­ç­‰
        }
        for name, info in sorted_restaurants
    ]
}

with open('data/extracted_from_titles_kimi.json', 'w') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)

print(f'\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° data/extracted_from_titles_kimi.json')
