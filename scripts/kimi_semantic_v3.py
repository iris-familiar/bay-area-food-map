#!/usr/bin/env python3
"""
Kimiè¯­ä¹‰æå– v3 - å¸¦Unique IDå»é‡
èšåˆæ—¶åŸºäºå”¯ä¸€IDè®¡æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
"""
import json
import re
from pathlib import Path
from collections import defaultdict

def parse_mcp_post(filepath):
    """è§£æMCPæ ¼å¼çš„postæ–‡ä»¶"""
    with open(filepath) as f:
        wrapper = json.load(f)
    content_text = wrapper['result']['content'][0]['text']
    data = json.loads(content_text)
    return data['data']['note'], data['data']['comments']['list']

def is_valid_restaurant_name(name):
    """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„é¤å…å"""
    if not name or len(name) < 2:
        return False
    
    # è¿‡æ»¤çº¯emoji
    emoji_pattern = re.compile(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251]+')
    if emoji_pattern.fullmatch(name):
        return False
    
    # è¿‡æ»¤å¸¸è§è¡¨æƒ…ç¬¦å·åç§°
    invalid_names = ['R', 'doge', 'è¯·æ–‡æ˜', 'è¯·å‹å¥½', 'ç§ä¿¡', 'èŒèŒå“’', 'è‰²è‰²', 'æ´¾å¯¹', 
                     'ç‚¹èµ', 'æ»¡æœˆ', 'ç¬‘å“­', 'å¾—æ„', 'çš±çœ‰', 'æ‚è„¸', 'å¹æ°”', 'ç©çš„ä»»é€‰', 'åèˆŒå¤´']
    if name in invalid_names or any(inv in name for inv in invalid_names):
        return False
    
    # è¿‡æ»¤çº¯è‹±æ–‡çŸ­è¯
    if name.isalpha() and len(name) < 4:
        return False
    
    # è¿‡æ»¤æè¿°æ€§è¯è¯­
    desc_words = ['çš„æ—¶å€™', 'å»è¿‡', 'å‘ç°', 'è¿™å®¶', 'çš„æ—¶å€™', 'å°±å»', 'åƒè¿‡', 'ä¸€æ¬¡', 'ä¹‹å']
    if any(word in name for word in desc_words):
        return False
    
    return True

def kimi_extract_restaurants_v3(note, comments):
    """
    Kimiè¯­ä¹‰æå– v3
    ä»å¸–å­å’Œè¯„è®ºä¸­æå–é¤å…ä¿¡æ¯
    è¿”å›ç»“æ„åŒ–æ•°æ®
    """
    title = note.get('title', '')
    content = note.get('desc', '')
    note_id = note.get('noteId', '')
    
    extracted = {
        'restaurants': [],
        'engagement': {
            'liked_count': int(note.get('interactInfo', {}).get('likedCount', 0) or 0),
            'collected_count': int(note.get('interactInfo', {}).get('collectedCount', 0) or 0),
            'comment_count': int(note.get('interactInfo', {}).get('commentCount', 0) or 0),
            'share_count': int(note.get('interactInfo', {}).get('sharedCount', 0) or 0)
        },
        'unique_ids': {
            'post_id': note_id,
            'comment_ids': [c['id'] for c in comments if c.get('id')]
        }
    }
    
    restaurants = []
    
    # 1. ç›´æ¥æ ‡æ³¨çš„é¤å…å ã€XXXã€‘
    pattern1 = r'[ã€\[]([^ã€‘\[\]]{2,20})[ã€‘\]]'
    matches = re.findall(pattern1, content)
    for m in matches:
        if is_valid_restaurant_name(m.strip()):
            restaurants.append({
                'name': m.strip(),
                'confidence': 0.95,
                'method': 'bracket_marker',
                'context': content[:200]
            })
    
    # 2. æ¢è¡Œåçš„é¤å…åï¼ˆå¸¸è§äºåˆ—è¡¨ï¼‰
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        match = re.match(r'^(?:\d+[\.\-]\s*|[-â€¢*]\s*)([\u4e00-\u9fa5\w\s]{2,15})(?:\s|$)', line)
        if match:
            name = match.group(1).strip()
            if is_valid_restaurant_name(name):
                restaurants.append({
                    'name': name,
                    'confidence': 0.90,
                    'method': 'list_pattern',
                    'context': line
                })
    
    # 3. ä»è¯„è®ºä¸­æå–æ¨è
    for comment in comments:
        comment_content = comment.get('content', '')
        comment_id = comment.get('id', '')
        
        # è¯„è®ºä¸­çš„æ¨èæ¨¡å¼
        if any(kw in comment_content for kw in ['æ¨è', 'ä¸é”™', 'å¥½åƒ', 'å¯ä»¥è¯•è¯•']):
            # æå–å¯èƒ½æåˆ°çš„é¤å…
            match = re.search(r'([\u4e00-\u9fa5]{2,8}(?:é¤å…|åº—|é¦†|å®¶|å°é¦†))', comment_content)
            if match:
                name = match.group(1).strip()
                if is_valid_restaurant_name(name):
                    restaurants.append({
                        'name': name,
                        'confidence': 0.75,
                        'method': 'comment_recommendation',
                        'context': comment_content[:100],
                        'from_comment_id': comment_id
                    })
    
    extracted['restaurants'] = restaurants
    return extracted

def aggregate_with_dedup(all_extractions):
    """
    èšåˆå»é‡ - ä½¿ç”¨Unique ID
    """
    # æŒ‰é¤å…åèšåˆ
    restaurant_data = defaultdict(lambda: {
        'mentions': [],
        'unique_post_ids': set(),
        'unique_comment_ids': set(),
        'total_engagement': {'posts': 0, 'comments': 0, 'collected': 0, 'shares': 0},
        'contexts': []
    })
    
    for extraction in all_extractions:
        post_id = extraction['unique_ids']['post_id']
        comment_ids = extraction['unique_ids']['comment_ids']
        engagement = extraction['engagement']
        
        for restaurant in extraction['restaurants']:
            name = restaurant['name']
            
            # ä½¿ç”¨Setå»é‡ - ç¡®ä¿åŒä¸€å¸–å­ä¸ä¼šé‡å¤è®¡æ•°
            if post_id not in restaurant_data[name]['unique_post_ids']:
                restaurant_data[name]['unique_post_ids'].add(post_id)
                restaurant_data[name]['mentions'].append({
                    'post_id': post_id,
                    'confidence': restaurant['confidence'],
                    'method': restaurant['method'],
                    'context': restaurant['context'][:150]
                })
                # åªåŠ ä¸€æ¬¡äº’åŠ¨æ•°æ®ï¼ˆæŒ‰å¸–å­ï¼‰
                restaurant_data[name]['total_engagement']['posts'] += 1
                restaurant_data[name]['total_engagement']['collected'] += engagement['collected_count']
            
            # è¯„è®ºIDå»é‡
            for cid in comment_ids:
                if cid and cid not in restaurant_data[name]['unique_comment_ids']:
                    restaurant_data[name]['unique_comment_ids'].add(cid)
                    restaurant_data[name]['total_engagement']['comments'] += 1
    
    return restaurant_data

if __name__ == '__main__':
    posts_dir = Path('data/raw/v2/posts/')
    
    all_extractions = []
    total_posts = 0
    
    print('ğŸ¤– Kimiè¯­ä¹‰æå– v3 - å¸¦Unique IDå»é‡')
    print('=' * 70)
    
    for f in sorted(posts_dir.glob('*.json')):
        try:
            note, comments = parse_mcp_post(f)
            total_posts += 1
            
            extraction = kimi_extract_restaurants_v3(note, comments)
            
            if extraction['restaurants']:
                all_extractions.append(extraction)
                if len(all_extractions) <= 3:
                    print(f"\nğŸ“ {note.get('title', 'N/A')[:40]}")
                    for r in extraction['restaurants'][:3]:
                        print(f"   âœ… {r['name']} ({r['method']})")
                    print(f"   ğŸ“Š å¸–å­ID: {extraction['unique_ids']['post_id'][:20]}...")
                    print(f"   ğŸ“Š è¯„è®ºæ•°: {len(extraction['unique_ids']['comment_ids'])}")
                    
        except Exception as e:
            pass
    
    print(f'\n{"="*70}')
    print(f'ä»{total_posts}æ¡å¸–å­ä¸­æå–äº† {len(all_extractions)} æ¡mentionè®°å½•')
    
    # èšåˆå»é‡
    aggregated = aggregate_with_dedup(all_extractions)
    
    # è¿‡æ»¤ä½è´¨é‡çš„
    valid_restaurants = {
        k: v for k, v in aggregated.items() 
        if len(v['unique_post_ids']) >= 1
    }
    
    sorted_restaurants = sorted(
        valid_restaurants.items(),
        key=lambda x: len(x[1]['unique_post_ids']),
        reverse=True
    )[:20]
    
    print(f'\nğŸ¯ èšåˆå»é‡å: {len(valid_restaurants)} å®¶é¤å…')
    print(f'\nTop 20ï¼ˆæŒ‰Unique Post IDæ•°ï¼‰:')
    for i, (name, info) in enumerate(sorted_restaurants, 1):
        unique_posts = len(info['unique_post_ids'])
        unique_comments = len(info['unique_comment_ids'])
        mentions = len(info['mentions'])
        print(f'{i:2d}. {name}')
        print(f'    å¸–å­æ•°:{unique_posts} | è¯„è®ºæ•°:{unique_comments} | æåŠè®°å½•:{mentions}')
    
    # ä¿å­˜
    result = {
        'extracted_by': 'Kimi_semantic_v3_unique_id_dedup',
        'total_posts': total_posts,
        'extractions_count': len(all_extractions),
        'restaurants_count': len(valid_restaurants),
        'restaurants': [
            {
                'name': name,
                'unique_post_count': len(info['unique_post_ids']),
                'unique_comment_count': len(info['unique_comment_ids']),
                'mention_records': len(info['mentions']),
                'engagement': info['total_engagement'],
                'contexts': [m['context'] for m in info['mentions'][:3]]
            }
            for name, info in sorted_restaurants
        ]
    }
    
    with open('data/extracted_restaurants_kimi_v3.json', 'w') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f'\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° data/extracted_restaurants_kimi_v3.json')
